{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import corpus, stream, note, midi\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Encoding_BACH_From_Score(): #编码器\n",
    "    \n",
    "    def __init__(self, appointed_voice_part = 0, min_tick = 0.25, key_mode = 'major'):\n",
    "        \n",
    "        self.appointed_voice_part = appointed_voice_part #给定的声部\n",
    "        self.min_tick = min_tick #最小时间单位\n",
    "        self.key_mode = key_mode #调性（大调或小调）\n",
    "        self.song_list = [] #输入曲目总表\n",
    "        self.data_max = -100 #指定声部的音高最大值\n",
    "        self.data_min = 100 #指定声部的音高最小值\n",
    "        self.target_max = -100 #其他声部的音差最大值\n",
    "        self.target_min = 100 #其他声部的音差最小值\n",
    "        self.trans_pitch = {'A- major':4, 'E- major':-3, 'B- major':2, 'F major':7, 'C major':0, \\\n",
    "                            'G major':5, 'D major':-2, 'A major':3, 'E major':-4, } #移调字典\n",
    "        \n",
    "    def get_appointed_part(self, song): #对指定声部编码\n",
    "        \n",
    "        appointed_part = [] #准备提取给定声部\n",
    "        now_tick = 0 #初始时间指针\n",
    "        for note in song.parts[self.appointed_voice_part].flat.notes: #对每个音符逐步编码并加入指定声部列表\n",
    "            while note.offset > now_tick: #处理休止符\n",
    "                appointed_part.append([now_tick, 0, 1]) #利用三个维度表示音的状态\n",
    "                now_tick += self.min_tick\n",
    "            note_duration_tick = int(note.duration.quarterLength / self.min_tick) #计算每个音持续多少最小时间单位\n",
    "            note_pitch = note.pitches[0].midi #得到该音符的音高数（返回值为整数，在0-127之间）\n",
    "            #考虑遍历计算得到data集合音域宽度\n",
    "            if note_pitch != 0: #0值pitch在music21中为休止，没有音高\n",
    "                if note_pitch > self.data_max:\n",
    "                    self.data_max = note_pitch\n",
    "                if note_pitch < self.data_min:\n",
    "                    self.data_min = note_pitch\n",
    "            for tick in range(note_duration_tick): #以最小时间为单位添加音符状态\n",
    "                if tick == 0:\n",
    "                    appointed_part.append([now_tick, note_pitch, 1]) #新音符的第三维状态为1\n",
    "                else:\n",
    "                    appointed_part.append([now_tick, note_pitch, 0]) #若持续则第三维状态为0\n",
    "                now_tick += self.min_tick #时间指针前进\n",
    "        \n",
    "        return appointed_part #返回被提取声部列表\n",
    "    \n",
    "    def pitch_diff(self, base_pitch, new_pitch): #比较两个音相差的半音数\n",
    "        \n",
    "        if base_pitch*new_pitch == 0: #休止符不比较\n",
    "            return 0\n",
    "        else:\n",
    "            return new_pitch-base_pitch  \n",
    "    \n",
    "    def get_other_parts(self, song): #获取所有编码后的谱面信息\n",
    "        \n",
    "        appointed_part = self.get_appointed_part(song) #获取指定声部列表\n",
    "        uncoded_part = list(range(4))\n",
    "        uncoded_part.remove(self.appointed_voice_part) #得到还未编码的声部\n",
    "        \n",
    "        for voice_index in uncoded_part: #对其他声部循环\n",
    "            part_note = song.parts[voice_index].flat.notes #得到其他某一个声部中所有音的信息\n",
    "            note_index = 0 #初始化音符指针\n",
    "            for encoded_tick in appointed_part: #对指定声部循环,更新列表信息\n",
    "                now_tick = encoded_tick[0] #获取当前时间指针\n",
    "                now_note = part_note[note_index] #获取当前时间所对应的音\n",
    "                if now_note.offset + now_note.duration.quarterLength <= now_tick: #时间指针达到或超过音符指针\n",
    "                    note_index += 1 #音符指针前进\n",
    "                now_note = part_note[note_index] #查看是否音符指针是否前进，若是，则立即更新\n",
    "                part_note_pitch = now_note.pitches[0].midi #获取当前时间点的音高\n",
    "                if now_note.offset == now_tick: #新音符的第2个状态为1\n",
    "                    encoded_tick.extend([self.pitch_diff(encoded_tick[1], part_note_pitch), 1])\n",
    "                elif now_note.offset < now_tick: #若持续则第2个状态为0\n",
    "                    encoded_tick.extend([self.pitch_diff(encoded_tick[1], part_note_pitch), 0])\n",
    "                else: #补充休止符\n",
    "                    encoded_tick.extend([0, 1])\n",
    "                #考虑遍历计算得到target集合音差宽度，休止符不算\n",
    "                if encoded_tick[1]*part_note_pitch != 0:\n",
    "                    if self.pitch_diff(encoded_tick[1], part_note_pitch) > self.target_max:\n",
    "                        self.target_max = self.pitch_diff(encoded_tick[1], part_note_pitch)\n",
    "                    if self.pitch_diff(encoded_tick[1], part_note_pitch) < self.target_min:\n",
    "                        self.target_min = self.pitch_diff(encoded_tick[1], part_note_pitch)\n",
    "                    \n",
    "        return appointed_part #返回全套列表（虽然名称叫appointed_part）\n",
    "    \n",
    "    def get_all_chorales(self):\n",
    "        \n",
    "        for chorale in corpus.chorales.Iterator(returnType='filename'): #这是巴赫众赞歌材料包，详情见官网\n",
    "            song = corpus.parse(chorale) #加载该首合唱的全部信息\n",
    "            if len(song.parts) == 4 and song.analyze('key').mode == self.key_mode:\n",
    "                old_tune = str(song.analyze('key'))\n",
    "                #若为指定的声部数量和调性才执行\n",
    "                song.transpose(self.trans_pitch[str(song.analyze('key'))], inPlace = True) #调性归一化\n",
    "                get_temp = self.get_other_parts(song)\n",
    "                if len(get_temp) <= 450: #若过长则删去（选450的原因用matplotlib画一下分布就知道了）\n",
    "                    self.song_list.append(get_temp) #加入新的乐曲\n",
    "                    print('%4d: %20s, %10s → %6s'%(len(self.song_list), chorale, \\\n",
    "                                                        old_tune, song.analyze('key')))\n",
    "                    \n",
    "        return self.song_list #返回所有曲目编码列表\n",
    "    \n",
    "    def get_dataset(self): #数据集再编码后准备输入网络\n",
    "        \n",
    "        song_tick_length,X,Y = [],[],[] #分别定义时间长度列表，训练集{X,Y}\n",
    "        for song in self.song_list: song_tick_length.append(len(song)) #获取每首乐曲的时间总长\n",
    "        max_song_tick_length = int(np.max(np.array(song_tick_length)))\n",
    "        print('最大长度为：%d 曲目量为：%d'%(max_song_tick_length,len(self.song_list)))\n",
    "        #准备第二次编码\n",
    "        for song in self.song_list:\n",
    "            x,y = [],[]\n",
    "            for song_tick in song:\n",
    "                #利用局部oneHot编码对输入集合进行再次编码\n",
    "                oneHot = [0]*(self.data_max - self.data_min + 1) #data音域宽度\n",
    "                if song_tick[1] != 0: oneHot[song_tick[1] - self.data_min] = 1 #oneHot编码\n",
    "                oneHot.append(song_tick[2])\n",
    "                x.append(oneHot) #加入是否连续的信息\n",
    "                #利用局部oneHot编码对其他声部集合进行再次编码\n",
    "                other_parts = [] #准备填充其他声部的编码信息\n",
    "                for part in range(3):\n",
    "                    part_index = 3 + part*2 #参见原先第一次编码方式即可知\n",
    "                    oneHot = [0]*(self.target_max - self.target_min + 1) #target音差宽度\n",
    "                    if song_tick[part_index] != 0: oneHot[song_tick[part_index] - self.target_min] = 1\n",
    "                    oneHot.append(song_tick[part_index + 1])\n",
    "                    other_parts.append(oneHot)\n",
    "                y.append(other_parts)\n",
    "            #准备padding操作\n",
    "            padding_length = max_song_tick_length - len(x) #序列需要padding的长度\n",
    "            for turn in range(padding_length):\n",
    "                x.append([0]*(self.data_max - self.data_min + 2)) #data集合的填充\n",
    "                y.append([[0]*(self.target_max - self.target_min + 2)]*3) #target集合的填充\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        #此处进行格式转换（因为上面一些玄学的原因导致第三层是list类型的表，有人知道怎么直接弄请告诉我）\n",
    "        npX,npY = [],[]\n",
    "        for i in range(len(self.song_list)):\n",
    "            for j in range(max_song_tick_length):\n",
    "                for k in range(self.data_max - self.data_min + 2): #其实为种类数+1的值，只是计算种类有一个加1\n",
    "                    npX.append(X[i][j][k])\n",
    "        for i in range(len(self.song_list)):\n",
    "            for j in range(max_song_tick_length):\n",
    "                for k in range(3): #注意此处还有一维\n",
    "                    for m in range(self.target_max - self.target_min + 2):\n",
    "                        npY.append(Y[i][j][k][m])\n",
    "        #制作词典，准备返回数据集\n",
    "        dataset = {'data': np.array(npX).reshape(len(self.song_list),\\\n",
    "                            max_song_tick_length,(self.data_max - self.data_min + 2)), \\\n",
    "                   'target': np.array(npY).reshape(len(self.song_list),\\\n",
    "                            max_song_tick_length,3,(self.target_max - self.target_min + 2)), \\\n",
    "                   'seq_length': np.array(song_tick_length)}\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def load_new_chorales(self, song): \n",
    "        \n",
    "        song = corpus.parse(song) #加载音乐信息\n",
    "        song.transpose(self.trans_pitch[str(song.analyze('key'))], inPlace = True) #移调\n",
    "        get_temp = self.get_other_parts(song) #得到四声部第一次编码结果\n",
    "        self.song_list.append(get_temp) #加入song_list的尾部\n",
    "    \n",
    "    def get_new_input_and_length(self):\n",
    "        \n",
    "        new_dataset = self.get_dataset() #此时song_list已经更新\n",
    "        in_put = new_dataset['data'][-5:] #由于是加入song_list的尾部，又每批是5个，故取后五个值\n",
    "        seq_length = new_dataset['seq_length'][-5:]\n",
    "        \n",
    "        return in_put,seq_length #返回批次的信息，最后一个是需要预测的音乐\n",
    "################################################################################################################\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import tensorflow as tf\n",
    "\n",
    "class BACH_Net(nn.Module):\n",
    "    \n",
    "    #网络的基本结构较简单，3个有300个隐藏层的LSTM，然后加两个线性层，最后是一个激活层和归一化层\n",
    "    #LSTM非双向，双向做下来效果和单向差不多，但时间增加了，不划算\n",
    "    #损失函数是带有mask的交叉熵函数\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, max_length, lengths=[]):\n",
    "        super(BACH_Net,self).__init__()\n",
    "        self.lstm_layer = nn.LSTM(input_size,hidden_size,num_layers) #这里一定要搞清楚输入输出是什么，很重要\n",
    "        self.Softmax = nn.Softmax(dim=3) #在Pytorch的0.4.0版本及其之后的版本，Softmax必须指定维度\n",
    "        self.Sigmoid = nn.Sigmoid() #Sigmoid层\n",
    "        self.Linearmiddle = nn.Linear(hidden_size,hidden_size) #第一个线性层\n",
    "        self.Linearnote = nn.Linear(hidden_size,3*(output_size-1)) #第二个线性层中的音符层\n",
    "        self.Linearchangenote = nn.Linear(hidden_size,3*1) #第二个线性层中的换音层\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lengths = lengths #长度为5个，与batch数一致\n",
    "        self.max_length = max_length #是batch最大长度，不是序列padding后的，padding后长度都一样\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #下面其实就做了一件事，根据batch做动态rnn输入\n",
    "        #tensorflow里面只要调用dynamic_rnn就可以，但Pytorch不行\n",
    "        #注意Pytorch的pack_padded_sequence函数默认序列长度递减输入\n",
    "        #################################################################################\n",
    "        _, idx_sort = torch.sort(self.lengths, dim=0, descending=True)\n",
    "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
    "        length = torch.tensor(list(self.lengths[idx_sort])) #降序排列\n",
    "        x = x[:,:length[0]]\n",
    "        x_zeros = torch.zeros(5,self.max_length-length[0],self.hidden_size) #padding的长度\n",
    "        x = x.index_select(0, idx_sort)\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(x,length,batch_first=True)\n",
    "        x_packed,_ = self.lstm_layer(x_packed) #pack后的序列再输入lstm网络\n",
    "        x_padded = nn.utils.rnn.pad_packed_sequence(x_packed,batch_first=True)\n",
    "        x = x_padded[0].index_select(0, idx_unsort) #还原顺序\n",
    "        if self.max_length-length[0]!=0:\n",
    "            if torch.cuda.is_available():\n",
    "                x = torch.cat((x.cuda(),x_zeros.cuda()),1)\n",
    "            else:\n",
    "                x = torch.cat((x,x_zeros),1) #将原始序列与padding的0拼接起来\n",
    "        #################################################################################\n",
    "        x = torch.reshape(x, [-1,self.hidden_size]) #准备转入线性层\n",
    "        x = self.Linearmiddle(x) #传入第一层线性层\n",
    "        \n",
    "        notes = self.Linearnote(x)\n",
    "        #下面需要注意shape要匹配好\n",
    "        notes = self.Softmax(torch.reshape(notes,[5,self.max_length,3,(self.output_size-1)]))\n",
    "        changenote = self.Linearchangenote(x)\n",
    "        #changenote最后是一维，和note不一样\n",
    "        changenote = self.Sigmoid(torch.reshape(changenote,[5, self.max_length,3,1]))\n",
    "        \n",
    "        x = torch.cat((notes, changenote),3) #在最后一个维度进行拼接\n",
    "\n",
    "        return x\n",
    "\n",
    "class LossFunction(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "\n",
    "    def forward(self,p,t):\n",
    "        \n",
    "        #此处为交叉熵函数，定义很简单，但必须利用torch内置函数，才能自动求导反向传播\n",
    "        #比如在tensorflow中有clip截断函数，但torch中只能自己用数学方法凑出来，如下是我想的一个办法\n",
    "        c_e = t*torch.log(1e-10*(1-p>1e-10).float()+p.mul((p>1e-10).float()).mul((p<1.0).float())+\\\n",
    "                          1.0*(1-(p<1.0).float()).float())+ (1-t)*torch.log(1e-10*(1-(1-p)>1e-10).float()+\\\n",
    "        (1-p).mul(((1-p)>1e-10).float()).mul(((1-p)<1.0).float())+1.0*(1-((1-p)<1.0).float()).float())\n",
    "        c_e = -torch.sum(torch.sum(c_e,3),2) #此步为止为交叉熵定义，但此处需要有mask作用，避免padding值也算入误差\n",
    "        mask = torch.sign(torch.max(torch.max(torch.abs(t),3)[0],2)[0]) #此处维度需要看清楚，在哪一个维加\n",
    "        c_e*= mask #套上mask\n",
    "        c_e = torch.sum(c_e,1)\n",
    "        c_e/= torch.sum(mask,1) #输出列表\n",
    "\n",
    "        return torch.mean(c_e.float()) #输出实数\n",
    "################################################################################################################\n",
    "from music21 import corpus, stream, note, midi\n",
    "from Encoder import Encoding_BACH_From_Score\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Decoding_BACH_To_Score(): #解码器\n",
    "    \n",
    "    def __init__(self, Encoder, new_short_code = []):\n",
    "        \n",
    "        self.new_short_code = new_short_code #存放第一次解码后的信息\n",
    "        self.Encoder = Encoder #由于要用到前面编码器的内部信息，导入该实例（还是一个类）\n",
    "        \n",
    "    def decode_oneHot_to_short_code(self, new_song, new_result, continue_pro=0.5, change_pro=0.7):\n",
    "        #该函数的功能是进行第一次解码\n",
    "        #但是第一次解码的结果与第一次编码的结果是不一样的，后者是存储音差，前者是存储数组下标，需要第二次解码时再转换\n",
    "        self.new_short_code = []\n",
    "        old_pitches = [0]*3 #音符指针初始化\n",
    "        now_tick = 0 #时间指针初始化\n",
    "\n",
    "        for tick_index in range(len(new_song)): #对时间节点循环\n",
    "            tick = [now_tick, new_song[tick_index][1], new_song[tick_index][2]] #先加载给定声部信息\n",
    "            for part in range(3): #对声部循环\n",
    "                old_pitch = old_pitches[part] #记录上一次的音高\n",
    "                new_pitch = np.argmax(new_result[tick_index, part, :len(new_result[0][0])-1]) #返回下标\n",
    "                #此处的想法是，如果换音的概率不是太大，那么就不要换\n",
    "                whether_changenote = new_result[tick_index, part, -1] > change_pro\n",
    "                #这里与上面想法类似，如果概率最大的音的概率并不高，那么就保留前面那个音，这里用到了前一个音的音高信息\n",
    "                if new_result[tick_index, part, old_pitch] > continue_pro:\n",
    "                    pitch = old_pitch\n",
    "                elif not whether_changenote: #决定是不是changenote\n",
    "                    pitch = old_pitch\n",
    "                else: pitch = new_pitch #若上述判断都通过，那么此时就应当改变音的状态了\n",
    "                tick.append(pitch) #加入“音高”信息（其实为下标，不是真的音高）\n",
    "                tick.append(int(whether_changenote)) #加入连续信息\n",
    "                old_pitches[part] = pitch #保留此轮信息进入下一轮\n",
    "            self.new_short_code.append(tick)\n",
    "            now_tick += self.Encoder.min_tick #时间指针前进一个单位\n",
    "    \n",
    "    def change_tick(self, L, index):\n",
    "        #这个函数是用来处理get_score中的tick操作，目的是将给定声部的两个值调换至正确的位置\n",
    "        L_temp = L[1:3].copy() #copy则不会复制变量地址\n",
    "        L.pop(1)\n",
    "        L.pop(1) #因为前面index为1的已经不见了，所以还是去除现在index为1的\n",
    "        L.insert(index *2 + 1, L_temp[0]) #将给定声部信息插入到正确位置，以备第二次解码\n",
    "        L.insert(index *2 + 2, L_temp[1])\n",
    "\n",
    "        return L\n",
    "    \n",
    "    def get_score(self):\n",
    "        #该函数的功能是进行第二次解码，并输出到乐谱Score类型中\n",
    "        new_score = stream.Score() #建立空乐谱\n",
    "        #准备音符指针与声部初始化\n",
    "        new_notes = [] \n",
    "        for part in range(4):\n",
    "            new_score.insert(0, stream.Part())\n",
    "            new_notes.append('ready?')\n",
    "        for tick in self.new_short_code:\n",
    "            #调用函数交换至正确顺序，思考若不调换会有什么后果\n",
    "            tick = self.change_tick(tick, self.Encoder.appointed_voice_part) \n",
    "            for part_index in range(4): #对所有声部循环\n",
    "                part = new_score.parts[part_index] #加载声部信息\n",
    "                #准备使用下标索引\n",
    "                pitch_index = part_index *2 + 1\n",
    "                changenote_index = part_index *2 + 2\n",
    "                #若不换音，则延续上一个音\n",
    "                if new_notes[part_index] != 'ready?' and tick[changenote_index] == 0:\n",
    "                    new_notes[part_index].quarterLength += self.Encoder.min_tick\n",
    "                #如果要换音了\n",
    "                if tick[changenote_index] == 1:\n",
    "                    if tick[pitch_index] > 0: #非休止\n",
    "                        new_ready_note = note.Note() #创建新的音 \n",
    "                        new_notes[part_index] = new_ready_note\n",
    "                        new_ready_note.offset = tick[0] #offset为该音的位置，设置为当前时间指针\n",
    "                        if part_index == self.Encoder.appointed_voice_part:\n",
    "                            #直接索引到tick该音的midi音高\n",
    "                            new_ready_note.pitch.midi = tick[pitch_index]\n",
    "                        else:\n",
    "                            #此处的逻辑可能要草稿纸上画一画，需要完全弄清楚第一、第二次编码和第一次解码的输入输出才可以\n",
    "                            new_ready_note.pitch.midi = tick[self.Encoder.appointed_voice_part *2 + 1] \\\n",
    "                            + tick[pitch_index] + self.Encoder.target_min\n",
    "                        new_ready_note.quarterLength = self.Encoder.min_tick #调用最小时间单位设置长度\n",
    "                        part.append(new_ready_note)\n",
    "                    else:\n",
    "                        new_ready_note = note.Rest() #建立休止符\n",
    "                        new_notes[part_index] = new_ready_note #更新音符指针信息\n",
    "                        new_ready_note.offset = tick[0]\n",
    "                        new_ready_note.quarterLength = self.Encoder.min_tick\n",
    "                        part.append(new_ready_note) #休止符加入声部信息\n",
    "        \n",
    "        return new_score #返回Score类型乐谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import corpus, stream, note, midi #music21包\n",
    "from Encoder import Encoding_BACH_From_Score #编码器\n",
    "from Decoder import Decoding_BACH_To_Score #解码器\n",
    "from Network import BACH_Net,LossFunction #搭建的网络\n",
    "from torch.autograd import Variable\n",
    "import tensorflow as tf\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将巴赫编码器导入（part为0-3的整数，对应SATB声部，默认0）\n",
    "Encoder = Encoding_BACH_From_Score(appointed_voice_part=0)\n",
    "Encoder.get_all_chorales() #加载所有指定的众赞歌信息并进行第一次编码\n",
    "dataset = Encoder.get_dataset() #第二次编码后返回结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#保存训练数据，在服务器上运行时直接上传本地数据，免去安装music21包的过程\n",
    "np.save(file=\"train_data.npy\", arr=dataset['data'])\n",
    "np.save(file=\"train_target.npy\", arr=dataset['target'])\n",
    "np.save(file=\"train_length.npy\", arr=dataset['seq_length'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#直接加载保存的numpy数组\n",
    "dataset = {'data': np.load(file='train_data0.npy',allow_pickle=True) , \\\n",
    "           'target' : np.load(file='train_target0.npy',allow_pickle=True), \\\n",
    "           'seq_length' : np.load(file='train_length0.npy',allow_pickle=True)}\n",
    "'''\n",
    "var_x = Variable(torch.from_numpy(dataset['data'])).float() #加载输入数据\n",
    "var_y = Variable(torch.from_numpy(dataset['target'])).float() #加载目标数据\n",
    "var_s = Variable(torch.from_numpy(dataset['seq_length'])).int() #加载序列长度\n",
    "max_song = var_x.size()[0] #曲目量\n",
    "max_length = var_x.size()[1] #时间单位长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.set_device(0) #貌似服务器上不加这句会报错，因为没有指定哪一块GPU（要运行两次，第一次会报错）\n",
    "if torch.cuda.is_available(): #判断是否能用GPU加速\n",
    "    #定义搭建的模型与损失函数并初始化\n",
    "    model = BACH_Net(np.shape(dataset['data'])[2],300,np.shape(dataset['target'])[3],3,max_length).cuda()\n",
    "    criterion = LossFunction().cuda() #定义损失函数\n",
    "else:\n",
    "    model = BACH_Net(np.shape(dataset['data'])[2],300,np.shape(dataset['target'])[3],3,max_length)\n",
    "    criterion = LossFunction() \n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=3e-3) #定义优化器与学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#服务器训练用，但本地测试也可以用\n",
    "'''\n",
    "for epoch in range(1000):\n",
    "    print('第%d轮'%(epoch+1))\n",
    "    L=[]\n",
    "    for batchnum in range(math.floor(max_song / 5)): #分批训练，每批5个\n",
    "        batch_start = batchnum * 5\n",
    "        batch_end = batchnum * 5 + 5\n",
    "        batch_end = min(max_song, batch_end)\n",
    "        if torch.cuda.is_available():\n",
    "            batch_x = var_x[batch_start : batch_end].cuda()\n",
    "            batch_y = var_y[batch_start : batch_end].cuda()\n",
    "            batch_s = var_s[batch_start : batch_end].cuda()\n",
    "            #若Pytorch的版本为1.0+那么此处应当跳过某一个批次\n",
    "            #因为它含有具备最大有效长度的序列，在高版本中不允许出现，构建某一维为0的张量\n",
    "            #if batch_start == 50: continue\n",
    "        else:\n",
    "            batch_x = var_x[batch_start : batch_end]\n",
    "            batch_y = var_y[batch_start : batch_end]\n",
    "            batch_s = var_s[batch_start : batch_end]\n",
    "        model.lengths = batch_s #输入此批序列的有效\n",
    "        #torch.cuda.set_device(0) #运行两次，理由上面已经讲过了\n",
    "        out = model(batch_x) #该轮输出的预测结果\n",
    "        loss = criterion(out, batch_y) #计算损失偏差\n",
    "        #loss如果一直在某一个值周围徘徊，可以考虑重启网络，可能运气不好，初始化状态较差\n",
    "        #Pytorch的lstm是均匀分布初始化的，与tensorflow不同，详情见官网\n",
    "        print('%d~%d:'%(batch_start,batch_end),round(loss.item(),6))\n",
    "        optimizer.zero_grad() #梯度清零\n",
    "        loss.backward() #反向传播\n",
    "        optimizer.step() #优化器迭代\n",
    "        L.append(loss.item())\n",
    "    print('该轮平均误差为：%f'%round(np.mean(np.array(L)),6))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model,'model.pkl')\n",
    "model = torch.load('Model_S.pkl', map_location='cpu') #由于服务器是GPU训练的模型，本机若是CPU应如前备注\n",
    "#如果有Warning不用管，正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = 'bach/new.mxl' #新的旋律线，注意待填充的声部要和编码器初始化时的一致\n",
    "Encoder.load_new_chorales(song) #加载后进行第一次编码\n",
    "new_input, new_length = Encoder.get_new_input_and_length() #第二次编码后返回序列信息\n",
    "new_input = Variable(torch.from_numpy(new_input)).float()\n",
    "new_length = Variable(torch.from_numpy(new_length)).int()\n",
    "model.lengths = new_length\n",
    "new_result = model(new_input) #再次走一遍网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder = Decoding_BACH_To_Score(Encoder) #Encoder是最先定义的解码器，其中储存有先前的信息，此部进行第一次解码\n",
    "Decoder.decode_oneHot_to_short_code(Encoder.get_appointed_part(corpus.parse(song))\\\n",
    "                                    , new_result[4].detach().numpy()) #进行第二次解码，这里是取batch的最后一个\n",
    "new_score = Decoder.get_score() #生成Score类型的最终谱面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_score.write('path...') 保存谱面用这个\n",
    "new_score.show() #显示谱面\n",
    "new_score.show('midi') #显示音乐播放器"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
